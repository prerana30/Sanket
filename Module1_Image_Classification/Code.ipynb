{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2654 images belonging to 2 classes.\n",
      "Found 80 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SHRISTI\\AppData\\Local\\Temp\\ipykernel_24064\\3523344782.py:39: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  model.fit_generator(train, epochs=30, validation_data=val,verbose=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "21/21 [==============================] - 79s 3s/step - loss: 1.1501 - accuracy: 0.4250 - val_loss: 3.4347 - val_accuracy: 0.4875\n",
      "Epoch 2/30\n",
      "21/21 [==============================] - 65s 3s/step - loss: 0.6939 - accuracy: 0.5610 - val_loss: 0.9936 - val_accuracy: 0.6125\n",
      "Epoch 3/30\n",
      "21/21 [==============================] - 61s 3s/step - loss: 0.6638 - accuracy: 0.6262 - val_loss: 1.8315 - val_accuracy: 0.5250\n",
      "Epoch 4/30\n",
      "21/21 [==============================] - 62s 3s/step - loss: 0.5973 - accuracy: 0.6669 - val_loss: 0.7336 - val_accuracy: 0.7500\n",
      "Epoch 5/30\n",
      "21/21 [==============================] - 60s 3s/step - loss: 0.6047 - accuracy: 0.6899 - val_loss: 4.3585 - val_accuracy: 0.5250\n",
      "Epoch 6/30\n",
      "21/21 [==============================] - 63s 3s/step - loss: 0.6570 - accuracy: 0.6153 - val_loss: 0.9116 - val_accuracy: 0.6250\n",
      "Epoch 7/30\n",
      "21/21 [==============================] - 62s 3s/step - loss: 0.6237 - accuracy: 0.6323 - val_loss: 1.7545 - val_accuracy: 0.5625\n",
      "Epoch 8/30\n",
      "21/21 [==============================] - 63s 3s/step - loss: 0.5456 - accuracy: 0.7268 - val_loss: 0.5542 - val_accuracy: 0.7625\n",
      "Epoch 9/30\n",
      "21/21 [==============================] - 59s 3s/step - loss: 0.5083 - accuracy: 0.7476 - val_loss: 0.4920 - val_accuracy: 0.8250\n",
      "Epoch 10/30\n",
      "21/21 [==============================] - 61s 3s/step - loss: 0.3982 - accuracy: 0.8282 - val_loss: 0.4334 - val_accuracy: 0.8250\n",
      "Epoch 11/30\n",
      "21/21 [==============================] - 61s 3s/step - loss: 0.3832 - accuracy: 0.8206 - val_loss: 0.5990 - val_accuracy: 0.7500\n",
      "Epoch 12/30\n",
      "21/21 [==============================] - 61s 3s/step - loss: 0.3080 - accuracy: 0.8791 - val_loss: 0.4989 - val_accuracy: 0.8250\n",
      "Epoch 13/30\n",
      "21/21 [==============================] - 60s 3s/step - loss: 0.2280 - accuracy: 0.9152 - val_loss: 0.4997 - val_accuracy: 0.8125\n",
      "Epoch 14/30\n",
      "21/21 [==============================] - 61s 3s/step - loss: 0.1990 - accuracy: 0.9333 - val_loss: 0.4849 - val_accuracy: 0.8000\n",
      "Epoch 15/30\n",
      "21/21 [==============================] - 60s 3s/step - loss: 0.1867 - accuracy: 0.9352 - val_loss: 0.6162 - val_accuracy: 0.7625\n",
      "Epoch 16/30\n",
      "21/21 [==============================] - 60s 3s/step - loss: 0.1217 - accuracy: 0.9642 - val_loss: 1.0076 - val_accuracy: 0.6375\n",
      "Epoch 17/30\n",
      "21/21 [==============================] - 62s 3s/step - loss: 0.0924 - accuracy: 0.9781 - val_loss: 0.6675 - val_accuracy: 0.7250\n",
      "Epoch 18/30\n",
      "21/21 [==============================] - 60s 3s/step - loss: 0.0591 - accuracy: 0.9872 - val_loss: 0.4816 - val_accuracy: 0.8500\n",
      "Epoch 19/30\n",
      "21/21 [==============================] - 60s 3s/step - loss: 0.0453 - accuracy: 0.9917 - val_loss: 1.1067 - val_accuracy: 0.6750\n",
      "Epoch 20/30\n",
      "21/21 [==============================] - 60s 3s/step - loss: 0.0377 - accuracy: 0.9913 - val_loss: 0.7232 - val_accuracy: 0.7125\n",
      "Epoch 21/30\n",
      "21/21 [==============================] - 59s 3s/step - loss: 0.0693 - accuracy: 0.9763 - val_loss: 0.9878 - val_accuracy: 0.6750\n",
      "Epoch 22/30\n",
      "21/21 [==============================] - 59s 3s/step - loss: 0.0675 - accuracy: 0.9793 - val_loss: 0.6530 - val_accuracy: 0.7375\n",
      "Epoch 23/30\n",
      "21/21 [==============================] - 60s 3s/step - loss: 0.0520 - accuracy: 0.9864 - val_loss: 0.5997 - val_accuracy: 0.7750\n",
      "Epoch 24/30\n",
      "21/21 [==============================] - 59s 3s/step - loss: 0.0283 - accuracy: 0.9951 - val_loss: 1.1086 - val_accuracy: 0.6750\n",
      "Epoch 25/30\n",
      "21/21 [==============================] - 59s 3s/step - loss: 0.0192 - accuracy: 0.9977 - val_loss: 0.5034 - val_accuracy: 0.8000\n",
      "Epoch 26/30\n",
      "21/21 [==============================] - 60s 3s/step - loss: 0.0115 - accuracy: 0.9985 - val_loss: 0.6745 - val_accuracy: 0.8500\n",
      "Epoch 27/30\n",
      "21/21 [==============================] - 60s 3s/step - loss: 0.0093 - accuracy: 0.9985 - val_loss: 0.5312 - val_accuracy: 0.8250\n",
      "Epoch 28/30\n",
      "21/21 [==============================] - 79s 4s/step - loss: 0.0071 - accuracy: 0.9992 - val_loss: 0.6973 - val_accuracy: 0.7875\n",
      "Epoch 29/30\n",
      "21/21 [==============================] - 78s 4s/step - loss: 0.0048 - accuracy: 0.9996 - val_loss: 0.5788 - val_accuracy: 0.8250\n",
      "Epoch 30/30\n",
      "21/21 [==============================] - 78s 4s/step - loss: 0.0039 - accuracy: 0.9996 - val_loss: 0.5756 - val_accuracy: 0.8375\n"
     ]
    }
   ],
   "source": [
    "#Import necessary modules for building and training the CNN Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, InputLayer, BatchNormalization, Dropout  #import various types of layers \n",
    "\n",
    "#imports the ImageDataGenerator class from Keras, which is used for loading and preprocessing images.\n",
    "from keras.preprocessing.image import ImageDataGenerator \n",
    "\n",
    "# create an instance of the 'ImageDataGenerator'\n",
    "imagegen = ImageDataGenerator()\n",
    "\n",
    "# loads the training data from the directory\n",
    "train = imagegen.flow_from_directory(r\"C:\\Users\\SHRISTI\\Documents\\GitHub\\Sanket\\Module1_Image_Classification\\train\", class_mode=\"categorical\", shuffle=False, batch_size=128, target_size=(224, 224))\n",
    "\n",
    "# loads the validation data from the directory\n",
    "val = imagegen.flow_from_directory(r\"C:\\Users\\SHRISTI\\Documents\\GitHub\\Sanket\\Module1_Image_Classification\\valid\", class_mode=\"categorical\", shuffle=False, batch_size=128, target_size=(224, 224))\n",
    "\n",
    "# build a sequential model and add an inputlayer to it with shape\n",
    "model = Sequential()\n",
    "model.add(InputLayer(input_shape=(224, 224, 3)))\n",
    "\n",
    "# add a Conv2D layer with 25 filters of size (5, 5), followed by a MaxPool2D layer with a pooling size of (2, 2) and same padding.\n",
    "model.add(Conv2D(25, (5, 5), activation='relu', strides=(1, 1), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "\n",
    "# add another Conv2D layer with 50 filters of size (5, 5), followed by a MaxPool2D layer with a pooling size of (2, 2) and same padding.\n",
    "model.add(Conv2D(50, (5, 5), activation='relu', strides=(2, 2), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# add another Conv2D layer with 70 filters of size (3, 3), followed by a MaxPool2D layer with a pooling size of (2, 2) and same padding.\n",
    "model.add(Conv2D(70, (3, 3), activation='relu', strides=(2, 2), padding='same'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2), padding='valid'))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# ANN block\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dense(units=100, activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# adds the output layer with 2 units/neurons and a softmax activation function\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "# compile model \n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
    "\n",
    "# fit on data for 30 epochs\n",
    "model.fit_generator(train, epochs=30, validation_data=val,verbose=1)\n",
    "\n",
    "#save the model\n",
    "model.save('my_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
